{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":25143,"status":"ok","timestamp":1659394182381,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"VNo1BLPvvAkA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"189d61b0-9e45-4f4e-9b19-174de99a7205"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 7.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 58.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 49.1 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 11.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting emoji\n","  Downloading emoji-2.0.0.tar.gz (197 kB)\n","\u001b[K     |████████████████████████████████| 197 kB 6.3 MB/s \n","\u001b[?25hBuilding wheels for collected packages: emoji\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-2.0.0-py3-none-any.whl size=193022 sha256=5e6c6686b3ebf11296d933a9b9efd0d86b5d44c15655fc6925a5736abaa722b3\n","  Stored in directory: /root/.cache/pip/wheels/ec/29/4d/3cfe7452ac7d8d83b1930f8a6205c3c9649b24e80f9029fc38\n","Successfully built emoji\n","Installing collected packages: emoji\n","Successfully installed emoji-2.0.0\n"]}],"source":["try:\n","    import transformers\n","except ImportError:\n","    !pip install transformers\n","    import transformers\n","try:\n","    import emoji\n","except ImportError:\n","    !pip install emoji\n","    import emoji"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1659394182382,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"BMbERrbndHVp"},"outputs":[],"source":["local = False\n","local_run = False"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8816,"status":"ok","timestamp":1659394191190,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"6YmcaSHFtnK9","outputId":"393d452b-bbe1-4fed-bc81-5f1e3b9bf233"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}],"source":["import pandas as pd\n","import tensorflow as tf\n","from transformers import AutoTokenizer, TFDistilBertForSequenceClassification\n","import pickle\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix,f1_score\n","\n","import random\n","import string\n","import re\n","import ast\n","\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","\n","import tensorflow_datasets as tfds\n","\n","if local_run:\n","    nltk.data.path.append('/Users/algin/VOLD/nltk_data')\n","    nltk.download('stopwords',download_dir='/Users/algin/VOLD/nltk_data')\n","    nltk.download('punkt',download_dir='/Users/algin/VOLD/nltk_data')\n","else:\n","    nltk.download('stopwords')\n","    nltk.download('punkt')\n","stop_words = set(stopwords.words('english'))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45407,"status":"ok","timestamp":1659394236589,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"20BL-YJ0FoAF","outputId":"73aa9d0e-b3a3-4dbc-cb57-b6a0633c75fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["if local:\n","    path = '/Users/algin/Greenwich/MSc Project/models/'\n","else:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    path = 'drive/MyDrive/MSc Data Science/MSc Project/models/'"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1659394236589,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"Joh6WALMcTvw"},"outputs":[],"source":["def get_emoji_regexp():\n","    # Sort emoji by length to make sure multi-character emojis are\n","    # matched first\n","    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n","    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n","    return re.compile(pattern)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1659394236590,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"cXrlbCfDKBTI"},"outputs":[],"source":["banned_list= string.punctuation\n","punctuation_reg_exp = \"[\" + banned_list + \"]\"\n","emoji_reg_exp = get_emoji_regexp()\n","\n","def stemmer(text):\n","    tokenized = nltk.word_tokenize(text)\n","    ps = PorterStemmer()\n","    return ' '.join([ps.stem(words) for words in tokenized])\n","\n","def clean_text(text):\n","    text = text.replace('\\r', '').replace('\\n', ' ').lower()\n","    text = re.sub(r\"(?:\\@|https?\\://)\\S+\", \"\", text)\n","\n","    text = [word for word in text.split() if word not in stop_words]\n","    text = ' '.join(text)\n","\n","    text = \" \".join(word.strip() for word in re.split('#(?!(?:hashtag)\\b)[\\w-]+(?=(?:\\s+#[\\w-]+)*\\s*$)', text))\n","    \n","    text = re.sub(punctuation_reg_exp,\"\",text)\n","\n","    text = re.sub(\"\\s\\s+\" , \" \", text)\n","\n","    text = re.sub(emoji_reg_exp, r\"\", text)\n","\n","    # text = stemmer(text)\n","    return text"]},{"cell_type":"markdown","metadata":{"id":"4Q_YbnK9fgyR"},"source":["**Load Dataset and transformations for XGBoost Model**"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":2032,"status":"ok","timestamp":1659394442882,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"IEribVeb_LUO"},"outputs":[],"source":["full_train_data = pd.read_csv(\"https://github.com/Voldegin/hate_speech_detection/blob/3-model-experiments/data/cleaned/cleaned_train_data.csv?raw=true\")\n","test_data = pd.read_csv(\"https://github.com/Voldegin/hate_speech_detection/blob/3-model-experiments/data/cleaned/cleaned_test_data.csv?raw=true\")"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659394442882,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"Eq50gLVF_eY_"},"outputs":[],"source":["train_data, val_data = train_test_split(full_train_data,test_size=5000,random_state=21)"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659394442883,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"9iRi28GvGP8j"},"outputs":[],"source":["def split_label_and_feature(data):\n","    return data['cleaned'], data['is_cyberbullying']"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659394443112,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"XdTKDEWJGbFl"},"outputs":[],"source":["X_train, y_train = split_label_and_feature(train_data)\n","X_val, y_val = split_label_and_feature(val_data)\n","X_test, y_test = split_label_and_feature(test_data)"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":1134,"status":"ok","timestamp":1659394444746,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"N9_i7lkNGu2U"},"outputs":[],"source":["clf = CountVectorizer()\n","X_train_cv =  clf.fit_transform(X_train)\n","\n","tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_cv)\n","X_train_tf = tf_transformer.transform(X_train_cv)"]},{"cell_type":"markdown","metadata":{"id":"P2YFwczkZ8sl"},"source":["**Prediction on Best XGB Model**"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1659394444747,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"nvoADcpEyrDC"},"outputs":[],"source":["file_name = path + \"best_xgb.pkl\"\n","xgb_model = pickle.load(open(file_name, \"rb\"))"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1659394444747,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"ZYAYnBT_F1eA","outputId":"ac223e85-ecbf-4f3f-bdf4-14e2a5723869"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'base_score': 0.5,\n"," 'booster': 'gbtree',\n"," 'colsample_bylevel': 1,\n"," 'colsample_bynode': 1,\n"," 'colsample_bytree': 0.6,\n"," 'gamma': 0.5,\n"," 'learning_rate': 0.06,\n"," 'max_delta_step': 0,\n"," 'max_depth': 10,\n"," 'min_child_weight': 1,\n"," 'missing': nan,\n"," 'n_estimators': 800,\n"," 'n_jobs': 1,\n"," 'nthread': None,\n"," 'objective': 'binary:logistic',\n"," 'random_state': 0,\n"," 'reg_alpha': 0,\n"," 'reg_lambda': 1,\n"," 'scale_pos_weight': 1,\n"," 'seed': None,\n"," 'silent': None,\n"," 'subsample': 0.8,\n"," 'verbosity': 1}"]},"metadata":{},"execution_count":44}],"source":["xgb_model.get_params()"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":0,"status":"ok","timestamp":1659394445172,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"1TsGEBddbGee"},"outputs":[],"source":["def xgb_prediction(text_list,preprocess=True):\n","    df = pd.Series(text_list)\n","    if preprocess:\n","        df = df.apply(clean_text)\n","    test_cv = clf.transform(df)\n","    test_tf = tf_transformer.transform(test_cv)\n","    predictions = xgb_model.predict(test_tf)\n","    return predictions"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1659394445715,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"Axs-i4mAblSQ","outputId":"62d950fc-5270-454b-fbd9-142219920c74"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0])"]},"metadata":{},"execution_count":46}],"source":["xgb_prediction([\"I believe in Christianity\"])"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1659394446144,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"qHWA5hYXb2kX","outputId":"154bba44-75d4-471a-c83b-0e9fd93b9e1d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0])"]},"metadata":{},"execution_count":47}],"source":["xgb_prediction([\"What a good day\"])"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1659394446830,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"q4_6IJPnb2kb","outputId":"dc69ca8e-471e-4f68-a59d-66b8c5d8e505"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0])"]},"metadata":{},"execution_count":48}],"source":["xgb_prediction([\"Muslims are terrorists\"])"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1659394447422,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"wI0Yie6lb2kc","outputId":"b84783e3-027f-41d4-bd37-cbd37f400a7a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0])"]},"metadata":{},"execution_count":49}],"source":["xgb_prediction([\"You are an asshole\"])"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":977,"status":"ok","timestamp":1659394448691,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"isaKcT7j0OAm"},"outputs":[],"source":["xgb_test_predictions = xgb_prediction(X_test,preprocess=False)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1659394448692,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"HFZVKdmA0RZ7","outputId":"93a50f88-09ca-4e2b-d24b-24db9369a03f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3477,   22],\n","       [2596,  899]])"]},"metadata":{},"execution_count":51}],"source":["confusion_matrix(y_test,xgb_test_predictions)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":214,"status":"ok","timestamp":1659394450188,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"MA4kK9Zi0SYe","outputId":"58893bad-e0e6-4523-e09e-2aa8f3d45286"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4071557971014493"]},"metadata":{},"execution_count":52}],"source":["f1_score(y_test,xgb_test_predictions)"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lqLZO4d9yh9B","executionInfo":{"status":"ok","timestamp":1659394460124,"user_tz":-60,"elapsed":219,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"}},"outputId":"eb3def1d-5792-4273-b5c6-1cc200efad40"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['malignant']                                                   1142\n","['malignant', 'rude', 'abuse']                                   475\n","['malignant', 'rude']                                            268\n","['malignant', 'abuse']                                           202\n","['malignant', 'highly_malignant', 'rude', 'abuse']                92\n","['rude']                                                          67\n","['abuse']                                                         64\n","['malignant', 'rude', 'abuse', 'loathe']                          59\n","['rude', 'abuse']                                                 50\n","['malignant', 'threat']                                           24\n","['malignant', 'loathe']                                           23\n","['malignant', 'abuse', 'loathe']                                  21\n","['malignant', 'highly_malignant', 'rude']                         16\n","['malignant', 'highly_malignant', 'rude', 'abuse', 'loathe']      14\n","['malignant', 'rude', 'threat', 'abuse']                          13\n","['threat']                                                        10\n","['malignant', 'highly_malignant']                                  9\n","['loathe']                                                         9\n","['abuse', 'loathe']                                                6\n","['malignant', 'highly_malignant', 'abuse']                         4\n","['malignant', 'highly_malignant', 'rude', 'threat', 'abuse']       4\n","['malignant', 'rude', 'loathe']                                    3\n","['malignant', 'rude', 'threat', 'abuse', 'loathe']                 3\n","['malignant', 'threat', 'loathe']                                  3\n","['malignant', 'highly_malignant', 'loathe']                        2\n","['rude', 'threat', 'abuse']                                        2\n","['malignant', 'threat', 'abuse', 'loathe']                         2\n","['malignant', 'highly_malignant', 'threat']                        2\n","['malignant', 'highly_malignant', 'rude', 'loathe']                1\n","['malignant', 'threat', 'abuse']                                   1\n","['malignant', 'rude', 'threat']                                    1\n","['malignant', 'highly_malignant', 'rude', 'threat']                1\n","['rude', 'abuse', 'loathe']                                        1\n","['rude', 'loathe']                                                 1\n","['malignant', 'highly_malignant', 'abuse', 'loathe']               1\n","Name: actual_value, dtype: int64"]},"metadata":{},"execution_count":54}],"source":["xgb_check = pd.concat([y_test,pd.Series(xgb_test_predictions)],axis=1)\n","xgb_check.columns = ['actuals','predictions']\n","fn_xgb = xgb_check[(xgb_check['actuals'] == 1) & (xgb_check['predictions'] == 0)]\n","fn_xgb_test_data = test_data.loc[fn_xgb.index]\n","fn_xgb_test_data['actual_value'].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"fhW1YLDEcl2t"},"source":["**Prediction on Transformer Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9193,"status":"ok","timestamp":1659381448203,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"qHiKyH-PtsYR","outputId":"7274a1f6-f926-45cd-8e83-3934f899a640"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at drive/MyDrive/MSc Data Science/MSc Project/models/distilbert--without-stem-94 were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Data Science/MSc Project/models/distilbert--without-stem-94 and are newly initialized: ['dropout_115']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["distilbert_model = TFDistilBertForSequenceClassification.from_pretrained(path + \"distilbert--without-stem-94\")\n","tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0uOmJ0kvGx1"},"outputs":[],"source":["def transformer_prediction(text_list,preprocess=True,return_one=False):  \n","    #tokenize the text\n","    if preprocess:\n","        new_list = []\n","        for each_text in text_list:\n","            new_list.append(clean_text(each_text))\n","    else:\n","        new_list = text_list\n","    encodings = tokenizer(new_list, \n","                          truncation=True, \n","                          padding=True)\n","    #transform to tf.Dataset\n","    dataset = tf.data.Dataset.from_tensor_slices((dict(encodings)))\n","    #predict\n","    preds = distilbert_model.predict(dataset.batch(1)).logits  \n","    \n","    #transform to array with probabilities\n","    res = tf.nn.softmax(preds, axis=1).numpy()\n","\n","    if return_one:\n","        return res.argmax(axis=1)  \n","    \n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":933,"status":"ok","timestamp":1659381449129,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"jffYGPU0vKaX","outputId":"d34c9480-a370-4c73-fad0-6cde3f94d9d4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[9.994949e-01, 5.051067e-04]], dtype=float32)"]},"metadata":{},"execution_count":97}],"source":["transformer_prediction([\"What a good day\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1659381449130,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"eKaCS-MQuX7k","outputId":"067c4bc4-d57c-4ea0-bab5-304253a7f0aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6.712463e-05, 9.999329e-01]], dtype=float32)"]},"metadata":{},"execution_count":98}],"source":["transformer_prediction([\"Muslims are terrorists\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2051,"status":"ok","timestamp":1659381451176,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"mBSoJPf4uhS7","outputId":"ee3c856e-83bf-45bc-a29c-a715eddac511"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.21792698, 0.782073  ]], dtype=float32)"]},"metadata":{},"execution_count":99}],"source":["transformer_prediction([\"You are an asshole\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1659381451177,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"Zu0R6N8euor5","outputId":"9b2464dc-cd32-4d0d-e9cd-ffdc12750148"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.7687712 , 0.23122883]], dtype=float32)"]},"metadata":{},"execution_count":100}],"source":["transformer_prediction([\"I believe in Christianity\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XS7me3DAo1Zk"},"outputs":[],"source":["check_X = X_test#.sample(100)\n","check_y = y_test[check_X.index]\n","check_X = check_X.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":205231,"status":"ok","timestamp":1659381656402,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"sv-Z6KSKe2h0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"464fdec1-e08f-487a-9f22-8f759fb3563d"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:5 out of the last 7000 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f884ec66560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}],"source":["distil_predictions = transformer_prediction(check_X,return_one=True,preprocess=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1659381656403,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"4rq0MXpOe2h1","outputId":"c8e9e7b2-3d73-4348-8c17-e2a44b8b6b3d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[3444,   55],\n","       [2459, 1036]])"]},"metadata":{},"execution_count":103}],"source":["confusion_matrix(check_y,distil_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1659381656403,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"i8HPpTcie2h1","outputId":"aa1415fc-58ef-446e-a7d9-350b883aba0e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.45180985608373314"]},"metadata":{},"execution_count":104}],"source":["f1_score(check_y,distil_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1659381656403,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"},"user_tz":-60},"id":"ezCBexPD-4aY","outputId":"7dc3f650-3dbf-4f97-f6e6-5f09397324fb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['malignant']                                                             1101\n","['malignant', 'rude', 'abuse']                                             416\n","['malignant', 'rude']                                                      265\n","['malignant', 'abuse']                                                     186\n","['malignant', 'highly_malignant', 'rude', 'abuse']                          83\n","['rude']                                                                    62\n","['abuse']                                                                   60\n","['malignant', 'rude', 'abuse', 'loathe']                                    57\n","['rude', 'abuse']                                                           45\n","['malignant', 'threat']                                                     23\n","['malignant', 'loathe']                                                     22\n","['malignant', 'abuse', 'loathe']                                            19\n","['malignant', 'highly_malignant', 'rude']                                   18\n","['malignant', 'rude', 'threat', 'abuse']                                    17\n","['malignant', 'highly_malignant', 'rude', 'abuse', 'loathe']                15\n","['malignant', 'highly_malignant']                                           10\n","['loathe']                                                                  10\n","['threat']                                                                   9\n","['abuse', 'loathe']                                                          6\n","['malignant', 'highly_malignant', 'abuse']                                   4\n","['malignant', 'rude', 'threat', 'abuse', 'loathe']                           4\n","['malignant', 'rude', 'loathe']                                              3\n","['malignant', 'threat', 'loathe']                                            3\n","['malignant', 'highly_malignant', 'rude', 'threat', 'abuse']                 3\n","['malignant', 'highly_malignant', 'rude', 'threat', 'abuse', 'loathe']       2\n","['malignant', 'highly_malignant', 'threat']                                  2\n","['malignant', 'threat', 'abuse', 'loathe']                                   2\n","['malignant', 'highly_malignant', 'loathe']                                  2\n","['malignant', 'highly_malignant', 'rude', 'loathe']                          2\n","['malignant', 'rude', 'threat']                                              2\n","['malignant', 'threat', 'abuse']                                             1\n","['malignant', 'highly_malignant', 'rude', 'threat']                          1\n","['rude', 'threat', 'abuse']                                                  1\n","['rude', 'abuse', 'loathe']                                                  1\n","['rude', 'loathe']                                                           1\n","['malignant', 'highly_malignant', 'abuse', 'loathe']                         1\n","Name: actual_value, dtype: int64"]},"metadata":{},"execution_count":105}],"source":["distil_check = pd.concat([check_y,pd.Series(distil_predictions)], axis=1)\n","distil_check.columns = ['actuals','predictions']\n","fn_distil = distil_check[(distil_check['actuals'] == 1) & (distil_check['predictions'] == 0)]\n","fn_distil_test_data = test_data.loc[fn_distil.index]\n","fn_distil_test_data['actual_value'].value_counts()"]},{"cell_type":"markdown","source":["**Prediction on Roberta Model**"],"metadata":{"id":"SXY1EeFaOA6A"}},{"cell_type":"code","source":["distilbert_model = TFDistilBertForSequenceClassification.from_pretrained(path + \"roberta\")\n","roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edLUO84Ywlz_","executionInfo":{"status":"ok","timestamp":1659381666270,"user_tz":-60,"elapsed":9881,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"}},"outputId":"e204250c-8d65-499f-b8f7-df5b0f964ab3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type roberta to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n","Some layers from the model checkpoint at drive/MyDrive/MSc Data Science/MSc Project/models/roberta were not used when initializing TFDistilBertForSequenceClassification: ['roberta', 'classifier/out_proj/bias:0', 'classifier/out_proj/kernel:0', 'classifier/dense/kernel:0', 'classifier/dense/bias:0']\n","- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at drive/MyDrive/MSc Data Science/MSc Project/models/roberta and are newly initialized: ['distilbert', 'dropout_153', 'pre_classifier', 'classifier/kernel:0', 'classifier/bias:0']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["batch_size = 64"],"metadata":{"id":"bQv1_XrmyUw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length = 128\n","def convert_example_to_feature(text):\n","  return roberta_tokenizer.encode_plus(text,\n","                                       add_special_tokens=True,\n","                                       max_length=max_length,\n","                                       pad_to_max_length=True,\n","                                       return_attention_mask=True,\n","  )\n","\n","def map_example_to_dict(input_ids, attention_masks, label):\n","    return {\n","      \"input_ids\": input_ids,\n","      \"attention_mask\": attention_masks,\n","           }, label\n","\n","def encode_examples(ds, limit=-1):\n","     # prepare list, so that we can build up final TensorFlow dataset from slices.\n","  input_ids_list = []\n","  attention_mask_list = []\n","  label_list = []\n","  if (limit > 0):\n","    ds = ds.take(limit)\n","  for text, label in tfds.as_numpy(ds):\n","    bert_input = convert_example_to_feature(text.decode())\n","    input_ids_list.append(bert_input['input_ids'])\n","    attention_mask_list.append(bert_input['attention_mask'])\n","    label_list.append([label])\n","  return tf.data.Dataset.from_tensor_slices((input_ids_list,\n","                                             attention_mask_list,\n","                              label_list)).map(map_example_to_dict)"],"metadata":{"id":"Wa6kpX2Xw6G0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_proba(text_list, model,return_one=True):\n","    df = pd.DataFrame(text_list, columns=['text'])\n","    df['label'] = 0\n","    sentences_modified = tf.data.Dataset.from_tensor_slices((df['text'],df['label']))\n","    ds_encoded = encode_examples(sentences_modified).batch(batch_size)\n","\n","    # preds_raw = tf.nn.softmax(model.predict(ds_encoded).logits)\n","    # preds = tf.math.argmax(preds_raw, axis=1)\n","\n","    preds = model.predict(ds_encoded).logits  \n","    \n","    #transform to array with probabilities\n","    res = tf.nn.softmax(preds, axis=1).numpy()\n","\n","    if return_one:\n","        return res.argmax(axis=1)  \n","    \n","    return res"],"metadata":{"id":"wfWcdbGTw2Qu"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xyn6xvD9uvSM"},"outputs":[],"source":["check_X = X_test#.sample(100)\n","check_y = y_test[check_X.index]\n","check_X = check_X.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tkljApKvAkGl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659381888547,"user_tz":-60,"elapsed":70067,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"}},"outputId":"dc63dd1f-7002-4632-e71c-8d7ba9fcf522"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}],"source":["roberta_predictions = predict_proba(check_X,distilbert_model,return_one=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OUrmcV6VApjn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659381888547,"user_tz":-60,"elapsed":22,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"}},"outputId":"cfe56565-3940-43dd-fb47-c0d10c1e6fde"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 356, 3143],\n","       [ 551, 2944]])"]},"metadata":{},"execution_count":116}],"source":["confusion_matrix(check_y,roberta_predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oYxLDOSkAtFU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659381888548,"user_tz":-60,"elapsed":16,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"}},"outputId":"be9e93ba-9d08-4c5e-9c11-7eb98feba987"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6144854936338969"]},"metadata":{},"execution_count":117}],"source":["f1_score(check_y,roberta_predictions)"]},{"cell_type":"code","source":["roberta_check = pd.concat([check_y,pd.Series(roberta_predictions)], axis=1)\n","roberta_check.columns = ['actuals','predictions']\n","fn_roberta = roberta_check[(roberta_check['actuals'] == 1) & (roberta_check['predictions'] == 0)]\n","fn_roberta_test_data = test_data.loc[fn_roberta.index]\n","fn_roberta_test_data['actual_value'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bEWVvYzyHER","executionInfo":{"status":"ok","timestamp":1659381888548,"user_tz":-60,"elapsed":12,"user":{"displayName":"Algin Joseph","userId":"03286840657949594849"}},"outputId":"70d112c3-fa99-45e2-f57f-f9a804f805e5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['malignant']                                                             189\n","['malignant', 'rude', 'abuse']                                            135\n","['malignant', 'rude']                                                      53\n","['malignant', 'abuse']                                                     50\n","['malignant', 'highly_malignant', 'rude', 'abuse']                         32\n","['malignant', 'rude', 'abuse', 'loathe']                                   19\n","['malignant', 'highly_malignant', 'rude', 'abuse', 'loathe']                9\n","['malignant', 'threat']                                                     9\n","['abuse']                                                                   8\n","['rude']                                                                    7\n","['malignant', 'loathe']                                                     6\n","['malignant', 'abuse', 'loathe']                                            4\n","['rude', 'abuse']                                                           4\n","['malignant', 'highly_malignant', 'rude']                                   4\n","['malignant', 'highly_malignant', 'rude', 'threat', 'abuse']                4\n","['malignant', 'highly_malignant']                                           4\n","['loathe']                                                                  3\n","['malignant', 'highly_malignant', 'loathe']                                 2\n","['malignant', 'highly_malignant', 'abuse']                                  2\n","['malignant', 'rude', 'threat', 'abuse', 'loathe']                          2\n","['malignant', 'rude', 'threat', 'abuse']                                    2\n","['malignant', 'threat', 'abuse', 'loathe']                                  1\n","['malignant', 'highly_malignant', 'rude', 'threat', 'abuse', 'loathe']      1\n","['threat']                                                                  1\n","Name: actual_value, dtype: int64"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":[""],"metadata":{"id":"4P6GPvxf3S5r"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Cyberbullying Detection Model Accuracy.ipynb","provenance":[],"authorship_tag":"ABX9TyMUvgS9nzJKMXJF2igwVl7K"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}